{{ define "upstream" }}
    {{ if .Address }}
        {{/* If we got the containers from swarm and this container's port is published to host, use host IP:PORT */}} 
        {{ $netLen := len .Container.Networks }}
        {{ if and .Container.Node.ID .Address.HostPort }}
            # {{ .Container.Node.Name }}/{{ .Container.Name }}
            server {{ .Container.Node.Address.IP }}:{{ .Address.HostPort }} fail_timeout=0;
        {{/* If there is no swarm node or the port is not published on host, check for Swarm network */}}        
        {{ else if eq $netLen 1}}
            # {{ .Container.Node.Name }}/{{ .Container.Name }} (Swarm Network)
			{{ $network := index .Container.Networks 0 }}   
            server {{ $network.IP }}:3000 fail_timeout=0;
        {{/* If there is no swarm node or the port is not published on host, use container's IP:PORT */}}
        {{ else }}
            # {{ .Container.Name }} (Direct)
            server {{ .Address.IP }}:{{ .Address.Port }} fail_timeout=0;
        {{ end }}
    {{ else }}
        # {{ .Container.Name }}
        server {{ .Container.IP }} down;
    {{ end }}
{{ end }}

user  nginx;
worker_processes  1;
daemon off;

error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;


events {
    worker_connections  1024;
  	accept_mutex off; # "on" if nginx worker_processes > 1
  	use epoll; # enable for Linux 2.6+
}


http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;

  	tcp_nopush on; # off may be better for *some* Comet/long-poll stuff
  	tcp_nodelay off; # on may be better for some Comet/long-poll stuff

	gzip on;
	gzip_http_version 1.0;
	gzip_proxied any;
	gzip_min_length 500;
	gzip_disable "MSIE [1-6]\.";
	gzip_types text/plain text/html text/xml text/css
	           text/comma-separated-values
	           text/javascript application/x-javascript
	           application/atom+xml;

	upstream app_server {
	  # fail_timeout=0 means we always retry an upstream even if it failed
	  # to return a good HTTP response (in case the unicorn master nukes a
	  # single worker for timing out).

    {{ range $container := and (whereLabelValueMatches $ "com.thehunt.role" "^app_server$") (whereLabelValueMatches $ "com.thehunt.partition" .Env.PARTITION) }}
          {{ $address := index $container.Addresses 0 }}
          {{ template "upstream" (dict "Container" $container "Address" $address) }}
    {{ end }}
                    
          # A placeholder to not crash NGINX if there are no valid servers
          server 1.2.3.4:3000 down;  
	}

	server {
	  listen 80 default deferred; # for Linux

	  # If you have IPv6, you'll likely want to have two separate listeners.
	  # One on IPv4 only (the default), and another on IPv6 only instead
	  # of a single dual-stack listener.  A dual-stack listener will make
	  # for ugly IPv4 addresses in $remote_addr (e.g ":ffff:10.0.0.1"
	  # instead of just "10.0.0.1") and potentially trigger bugs in
	  # some software.
	  # listen [::]:80 ipv6only=on; # deferred or accept_filter recommended

	  client_max_body_size 4G;
	  server_name _;

	  # ~2 seconds is often enough for most folks to parse HTML/CSS and
	  # retrieve needed images/icons/frames, connections are cheap in
	  # nginx so increasing this is generally safe...
	  keepalive_timeout 5;

	  # path for static files
	  root /usr/share/nginx/html;

	  # Prefer to serve static files directly from nginx to avoid unnecessary
	  # data copies from the application server.
	  #
	  # try_files directive appeared in in nginx 0.7.27 and has stabilized
	  # over time.  Older versions of nginx (e.g. 0.6.x) requires
	  # "if (!-f $request_filename)" which was less efficient:
	  # http://bogomips.org/unicorn.git/tree/examples/nginx.conf?id=v3.3.1#n127
	  try_files $uri/index.html $uri.html $uri @app;

	  location @app {
	    # an HTTP header important enough to have its own Wikipedia entry:
	    #   http://en.wikipedia.org/wiki/X-Forwarded-For
	    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

	    # enable this if you forward HTTPS traffic to unicorn,
	    # this helps Rack set the proper URL scheme for doing redirects:
	    # proxy_set_header X-Forwarded-Proto $scheme;

	    # pass the Host: header from the client right along so redirects
	    # can be set properly within the Rack application
	    proxy_set_header Host $http_host;

        # Queue length monitoring                                                                                                                                                                                                                                       
        proxy_set_header X-Request-Start "t=${msec}";

	    # we don't want nginx trying to do something clever with
	    # redirects, we set the Host: header above already.
	    proxy_redirect off;

	    # It's also safe to set if you're using only serving fast clients
	    # with unicorn + nginx, but not slow clients.  You normally want
	    # nginx to buffer responses to slow clients, even with Rails 3.1
	    # streaming because otherwise a slow client can become a bottleneck
	    # of unicorn.
	    #
	    # The Rack application may also set "X-Accel-Buffering (yes|no)"
	    # in the response headers do disable/enable buffering on a
	    # per-response basis.
	    # proxy_buffering off;

	    proxy_pass http://app_server;
	  }
	}
}

